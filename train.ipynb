{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70fb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import glob\n",
    "import re\n",
    "from typing import Dict, Tuple, List, Callable, Union\n",
    "\n",
    "import cloudpickle\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from nltk import ngrams, word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb2a677",
   "metadata": {},
   "source": [
    "# Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e8fd7f",
   "metadata": {
    "code_folding": [
     3,
     15
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "test_path = 'data/test/'\n",
    "\n",
    "def txt_to_df(folder: str) -> pd.DataFrame:\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    file_paths = glob.glob(folder + '/*.txt')\n",
    "    data = []\n",
    "    for path in tqdm(file_paths):\n",
    "        with open(path, encoding='utf-8') as file: \n",
    "            review = file.read()\n",
    "        id_review, rating = map(int, re.findall(pattern, path))\n",
    "        data.append((id_review, review, rating))\n",
    "        \n",
    "    return pd.DataFrame(data=data, columns=['id', 'text', 'rating']).set_index('id')\n",
    "    \n",
    "def load_data(train_path: str, test_path: str) -> Tuple[pd.DataFrame]:\n",
    "    train = pd.DataFrame()\n",
    "    print('Load train')\n",
    "    for sentiment in ['neg', 'pos', 'unsup']:\n",
    "        res = txt_to_df(train_path + sentiment)\n",
    "        res['sentiment'] = sentiment\n",
    "        train = train.append(res)\n",
    "        \n",
    "    test = pd.DataFrame()\n",
    "    print('Load test')\n",
    "    for sentiment in ['neg', 'pos']:\n",
    "        res = txt_to_df(test_path + sentiment)\n",
    "        res['sentiment'] = sentiment\n",
    "        test = test.append(res)\n",
    "        \n",
    "    return train.sort_index(), test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4653f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8194.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 12500/12500 [00:01<00:00, 8322.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 50000/50000 [00:04<00:00, 12304.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 12500/12500 [00:00<00:00, 13781.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 12500/12500 [00:00<00:00, 13339.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ae5580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I admit, the great majority of films released ...</td>\n",
       "      <td>0</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you like adult comedy cartoons, like South ...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a very strange film that was long thou...</td>\n",
       "      <td>0</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  rating sentiment\n",
       "id                                                                     \n",
       "0   Story of a man who has unnatural feelings for ...       3       neg\n",
       "0   Bromwell High is a cartoon comedy. It ran at t...       9       pos\n",
       "0   I admit, the great majority of films released ...       0     unsup\n",
       "1   If you like adult comedy cartoons, like South ...       7       pos\n",
       "1   This is a very strange film that was long thou...       0     unsup"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed44bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My boyfriend and I went to watch The Guardian....</td>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pale imitation of 'Officer and a Gen...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My yardstick for measuring a movie's watch-abi...</td>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  rating sentiment\n",
       "id                                                                     \n",
       "0   Once again Mr. Costner has dragged out a movie...       2       neg\n",
       "0   I went and saw this movie last night after bei...      10       pos\n",
       "1   My boyfriend and I went to watch The Guardian....      10       pos\n",
       "1   This is a pale imitation of 'Officer and a Gen...       3       neg\n",
       "2   My yardstick for measuring a movie's watch-abi...       7       pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd224295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "neg      12500\n",
       "pos      12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cdf930e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     5100\n",
       "10    4732\n",
       "8     3009\n",
       "4     2696\n",
       "7     2496\n",
       "3     2420\n",
       "2     2284\n",
       "9     2263\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.sentiment != 'unsup'].rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f8c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим дубликаты \n",
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83eded26",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Очистка текста\n",
    "def clean_text(documents: np.array, show_progress: bool = False) -> np.array:\n",
    "    documents = documents.copy()\n",
    "    snowball = SnowballStemmer(language='english')\n",
    "    n_iterations = tqdm(range(len(documents))) if show_progress else range(len(documents))\n",
    "    for i in n_iterations:\n",
    "        # При сентимент анализе твитов важной фичой было наличие разных смайлов, \n",
    "        # поэтому там нельзя было оставлять только буквы.\n",
    "        # Но в этой задаче мы оставляем только буквы, потому что качество не меняется.\n",
    "        text = documents[i]\n",
    "        text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "        doc = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем по словам\n",
    "        # делаем стемминг\n",
    "        # пробовал также удалять стоп слова но качество стало хуже\n",
    "        tokens = [snowball.stem(token) for token in doc] \n",
    "        text = \" \".join(tokens) # возвращаем строку\n",
    "        documents[i] = text\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb33749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 74412/74412 [03:20<00:00, 372.03it/s]\n"
     ]
    }
   ],
   "source": [
    "train['clean_text'] = clean_text(train.text.values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e02daacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup = train[train.sentiment != 'unsup']\n",
    "train_unsup = train[train.sentiment == 'unsup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad42785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sup.sentiment = (train_sup.sentiment == 'pos').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5de7b",
   "metadata": {},
   "source": [
    "# TF-IDF + Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4847f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32436"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(min_df=100, ngram_range=(1, 3), max_df=0.7, decode_error='ignore')\n",
    "tf_idf.fit(pd.concat((train_unsup.clean_text, train_sup.clean_text))) \n",
    "len(tf_idf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d78713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tf_idf = tf_idf.transform(train_sup.clean_text)\n",
    "y_sentiment = train_sup.sentiment\n",
    "y_rating = train_sup.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365bd1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best for sentiment:\n",
      "{'alpha': 6.866488450042999e-05} 0.8830966164549062\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best for rating\n",
      "{'alpha': 4.094915062380427e-05} 0.3637562810865326\n"
     ]
    }
   ],
   "source": [
    "lin_model = SGDClassifier(penalty='elasticnet', random_state=SEED, class_weight='balanced')\n",
    "\n",
    "params = {'alpha': np.logspace(-10, 1)}\n",
    "grid = GridSearchCV(lin_model, param_grid=params, scoring='f1_weighted',\n",
    "                   n_jobs=-1, cv=5, verbose=True)\n",
    "grid.fit(X_tf_idf, y_sentiment)\n",
    "print('Best for sentiment:')\n",
    "print(grid.best_params_, grid.best_score_)\n",
    "\n",
    "grid.fit(X_tf_idf, y_rating)\n",
    "print('Best for rating')\n",
    "print(grid.best_params_, grid.best_score_)\n",
    "# alpha почти не отличается от параметров по-умолчанию поэтому буду использовать 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a39655",
   "metadata": {},
   "source": [
    "# Doc2Vec + CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6b4310f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19523"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = 300\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_sup.clean_text.str.split())]\n",
    "doc2vec = Doc2Vec(documents=documents, \n",
    "                   vector_size=vector_size, window=5, min_count=5)\n",
    "\n",
    "len(doc2vec.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_to_vectors(documents: pd.Series, show_progress: bool = False) -> np.array:\n",
    "    vectors = []\n",
    "    documents = tqdm(documents.str.split()) if show_progress else documents.str.split()\n",
    "    for doc in documents:\n",
    "        vectors.append(doc2vec.infer_vector(doc))\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd129317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 24905/24905 [01:44<00:00, 237.46it/s]\n"
     ]
    }
   ],
   "source": [
    "X_doc2vec = documents_to_vectors(train_sup.clean_text, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2de9488",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model = CatBoostClassifier(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f0fe4",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e4386",
   "metadata": {
    "code_folding": [
     1,
     8
    ]
   },
   "outputs": [],
   "source": [
    "# И так, у нас две модели давайте попробуем их сравнить на кроссвалидации\n",
    "def cross_val_score(\n",
    "    model: Callable,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cv: Union[int, Tuple[int, int]],\n",
    "    random_state: int = 42,\n",
    "    show_progress: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cross-validation score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Callable :\n",
    "        model to train (e.g. RandomForestRegressor)\n",
    "\n",
    "    X: np.ndarray :\n",
    "\n",
    "    y: np.ndarray :\n",
    "\n",
    "    cv Union[int, Tuple[int, int]]:\n",
    "        (Default value = 5)\n",
    "        number of folds or (n_folds, n_repeats)\n",
    "        if int, then KFold is used\n",
    "        if tuple, then RepeatedKFold is used\n",
    "\n",
    "\n",
    "    random_state: int :\n",
    "        (Default value = 0)\n",
    "        random state for cross-validation\n",
    "\n",
    "    show_progress: bool :\n",
    "        (Default value = False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray :\n",
    "        cross-validation scores [n_folds]\n",
    "\n",
    "    \"\"\"\n",
    "    if type(cv) == int:\n",
    "        kf = StratifiedKFold(n_splits=cv, random_state=random_state, shuffle=True)\n",
    "    else:\n",
    "        kf = RepeatedStratifiedKFold(n_splits=cv[0], n_repeats=cv[1], random_state=random_state)\n",
    "        \n",
    "    splits = tqdm(kf.split(X, y)) if show_progress else kf.split(X, y)\n",
    "    scores = []\n",
    "    for train_ind, test_ind in splits:\n",
    "        X_train = X[train_ind]\n",
    "        y_train = y[train_ind]\n",
    "        X_test = X[test_ind]\n",
    "        y_test = y[test_ind]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf16d3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compare_two_models(models: Dict[str, Callable], \n",
    "                   X_data: Dict[str, np.ndarray], y: np.ndarray, cv: Tuple[int, int] = (3, 10),\n",
    "                   alpha: float = 0.05) -> Dict[str, np.ndarray]: \n",
    "    all_scores = {}\n",
    "    for model in models:\n",
    "        scores = cross_val_score(model=models[model], X=X_data[model], \n",
    "                                 y=y, cv=cv, show_progress=True)\n",
    "        all_scores[model] = scores\n",
    "    \n",
    "    _, p_value = ttest_rel(*all_scores.values())\n",
    "              \n",
    "    if p_value < alpha:\n",
    "        print('Модели значимо различаются между собой!!!')\n",
    "    else:\n",
    "        print('Модели значимо НЕ различаются между собой')    \n",
    "              \n",
    "    print('Средние значения на кроссвалидации...')\n",
    "    print(*[f'{k}: {round(v.mean(), 4)}'for k, v in all_scores.items()], sep='\\n')\n",
    "              \n",
    "    return all_scores\n",
    "\n",
    "name_models = ['tf-idf +  sgd', 'doc2vec + catboost']\n",
    "models = dict(zip(name_models, [lin_model, \n",
    "                                boost_model]))\n",
    "X_data = dict(zip(name_models, [X_tf_idf, X_doc2vec]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb5f08ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:28,  1.06it/s]\n",
      "30it [15:00, 30.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели значимо различаются между собой!!!\n",
      "Средние значения на кроссвалидации...\n",
      "tf-idf +  sgd: 0.8932\n",
      "doc2vec + catboost: 0.8322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores_sentiment = compare_two_models(models, X_data, y_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2139859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:31,  5.20s/it]\n",
      "6it [21:07, 211.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модели значимо различаются между собой!!!\n",
      "Средние значения на кроссвалидации...\n",
      "tf-idf +  sgd: 0.3973\n",
      "doc2vec + catboost: 0.3835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models[name_models[0]].fit(X_data[name_models[0]], y_sentiment)\n",
    "models[name_models[1]].fit(X_data[name_models[1]], y_sentiment)\n",
    "\n",
    "# Для предсказания рейтинга будем использовать предсказанный sentiment\n",
    "pred_lin = csr_matrix(models[name_models[0]].predict(X_data[name_models[0]]).reshape(-1, 1))\n",
    "X_data[name_models[0]] = csr_matrix(hstack((X_data[name_models[0]], pred_lin)))\n",
    "\n",
    "pred_boost = csr_matrix(models[name_models[1]].predict(X_data[name_models[1]]).reshape(-1, 1))\n",
    "X_data[name_models[1]] = csr_matrix(hstack((X_data[name_models[1]], pred_boost)))\n",
    "\n",
    "scores_rating = compare_two_models(models, X_data, y_rating.values, cv=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1f7e3",
   "metadata": {},
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c080159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f59b91b4f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим модели \n",
    "lin_model_sentiment = SGDClassifier(penalty='elasticnet', random_state=SEED, class_weight='balanced')\n",
    "lin_model_sentiment.fit(X_tf_idf, y_sentiment)\n",
    "lin_pred_sentiment = lin_model_sentiment.predict(X_tf_idf)\n",
    "lin_model_rating = SGDClassifier(penalty='elasticnet', random_state=SEED, class_weight='balanced')\n",
    "lin_model_rating.fit(csr_matrix(hstack((X_tf_idf, csr_matrix(lin_pred_sentiment.reshape(-1, 1))))),\n",
    "                     y_rating)\n",
    "\n",
    "boost_model_sentiment = CatBoostClassifier(verbose=False)\n",
    "boost_model_sentiment.fit(X_doc2vec, y_sentiment)\n",
    "boost_pred_sentiment = boost_model_sentiment.predict(X_doc2vec)\n",
    "boost_model_rating = CatBoostClassifier(verbose=False)\n",
    "boost_model_rating.fit(np.concatenate((X_doc2vec, boost_pred_sentiment.reshape(-1, 1)), axis=1),\n",
    "                       y_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95997696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_idf_sgd(texts: pd.Series) -> Dict[str, np.array]:\n",
    "    texts = texts.copy()\n",
    "    texts = pd.Series(clean_text(texts.values))\n",
    "    vectors = tf_idf.transform(texts)\n",
    "    sentiment = lin_model_sentiment.predict(vectors)\n",
    "    rating = lin_model_rating.predict(csr_matrix(hstack((vectors,\n",
    "                                                         csr_matrix(sentiment.reshape(-1, 1))))))\n",
    "    return {'sentiment': sentiment, 'rating': rating}\n",
    "                                      \n",
    "def predict_doc2vec_catboost(texts: pd.Series) -> Dict[str, np.array]:\n",
    "    texts = texts.copy()\n",
    "    texts = pd.Series(clean_text(texts.values))\n",
    "    vectors = documents_to_vectors(texts)\n",
    "    sentiment = boost_model_sentiment.predict(vectors)\n",
    "    rating = boost_model_rating.predict(np.concatenate((vectors, sentiment.reshape(-1, 1)), axis=1))\n",
    "    return {'sentiment': sentiment, 'rating': rating}\n",
    "\n",
    "def predict(texts: pd.Series, is_tf_idf: bool = True) -> Dict[str, np.array]:\n",
    "    \"\"\" Cross-validation score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: pd.Series :\n",
    "        texts for classification\n",
    "    \n",
    "    is_tf_idf: bool = True\n",
    "        shows which model we will use \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, np.array] :\n",
    "        results\n",
    "    \"\"\"\n",
    "    if is_tf_idf:\n",
    "        return predict_tf_idf_sgd(texts)\n",
    "    \n",
    "    return predict_doc2vec_catboost(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e6dc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/predict.bin', 'wb') as file:\n",
    "    cloudpickle.dump(predict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d299422",
   "metadata": {},
   "source": [
    "# Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea111e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/predict.bin', 'rb') as file:\n",
    "    predict_func = cloudpickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82cb36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sentiment = (test.sentiment == 'pos').astype(int)\n",
    "y_test_rating = test.rating\n",
    "\n",
    "y_pred_tf_idf = predict_func(test.text, is_tf_idf=True)\n",
    "y_pred_doc2vec = predict_func(test.text, is_tf_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d809e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "F1 Score tf_idf:  0.8992\n",
      "F1 Score doc2vec:  0.8158\n",
      "\n",
      "Rating\n",
      "F1 Score tf_idf:  0.3829\n",
      "F1 Score doc2vec:  0.3297\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment')\n",
    "print('F1 Score tf_idf: ', round(f1_score(y_test_sentiment, y_pred_tf_idf['sentiment']), 4))\n",
    "print('F1 Score doc2vec: ', round(f1_score(y_test_sentiment, y_pred_doc2vec['sentiment']), 4))\n",
    "print()\n",
    "\n",
    "print('Rating')\n",
    "print('F1 Score tf_idf: ', round(f1_score(y_test_rating, y_pred_tf_idf['rating'], average='weighted'), 4))\n",
    "print('F1 Score doc2vec: ', round(f1_score(y_test_rating, y_pred_doc2vec['rating'], average='weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae43c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
